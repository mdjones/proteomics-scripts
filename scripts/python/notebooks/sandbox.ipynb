{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Load any changes to local modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "pwd = %pwd\n",
    "project_dir = '{0}/../../../'.format(pwd)\n",
    "module_path = os.path.abspath(os.path.join(project_dir))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from IPython.display import display\n",
    "\n",
    "import sqlalchemy\n",
    "import sqlite3\n",
    "\n",
    "from nbcpact import AnalyzeQuantCompare,Peptide,PeptideGroup,UcbreUtils,PeptidesFromPeptideListBuilder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_path = \"../../../test/data/peptideList.csv\"\n",
    "peptide_generator = PeptidesFromPeptideListBuilder(peptide_list_file=file_path)\n",
    "peptides = peptide_generator.generate_peptides()\n",
    "pep = peptides[0]\n",
    "\n",
    "print(\"ip2_peptide={0}, sequence={1}, mod_locs={2}, ptm_indices={3}, area_ratio={4}\".format(pep.ip2_peptide, pep.sequence, pep.mod_locs, pep.ptm_indices, pep.area_ratio))\n",
    "print(\"area_ratios={0}, annotation={1}, uniprot_ids={2}, run_counter={3}\".format(pep.area_ratios, pep.annotation, pep.uniprot_ids, pep.run_counter))\n",
    "print(\"decoy={0},unique1={1}\".format(pep.decoy, pep.unique1))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "ip2_peptide=None, sequence=None, mod_locs=None, ptm_indices=None, area_ratio=None,\n",
    "                 area_ratios=None, annotation=None, uniprot_ids=None, run_counter=None, decoy=None,\n",
    "                 unique1=None\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class DataType(Enum):\n",
    "    Float = 1\n",
    "\n",
    "class PeptideFromPD2_1Generator:\n",
    "    \n",
    "    __psm_cys_mod_pattern = re.compile(r'C(\\d+)\\(isoTO\\w*\\)')\n",
    "    __exp_pattern = r'(KEA_EN80\\d)_\\d.raw'\n",
    "    __peptide_mod_pattern = re.compile(r'.*\\d.isoTOP TEV [heavyLight]+ \\[(.+)\\].*')\n",
    "    __peptide_cys_mod_pattern = re.compile(r'C(\\d+)')\n",
    "    \n",
    "    __data_cache = {}\n",
    "\n",
    "    \n",
    "    def __init__(self, pd_study_dir=\"/usca/asperapoc/NB-CPACT/NB-CPACT-NIBR/NIBR_loaded_UCB_EN80/Analysis/PD2.1/\"):\n",
    "        self.__pd_study_dir = pd_study_dir\n",
    "        # TODO: Look for the latest pdResult file\n",
    "        file_path = '{0}/{1}'.format(pd_study_dir, 'KEA_isoTOP_DN_All.pdResult')\n",
    "        self.__connection = sqlite3.connect(file_path)\n",
    "        self.__target_psms = self.get_target_psms()\n",
    "        modifications = self.get_found_modifications()\n",
    "        \n",
    "        value = float(modifications[modifications['Name'] == 'IsoTOP heavy']['DeltaMonoisotopicMass'])\n",
    "        self.__isoTopHeavyMass = \"{0:.2f}\".format(value)\n",
    "        value = float(modifications[modifications['Name'] == 'IsoTOP light']['DeltaMonoisotopicMass'])\n",
    "        self.__isoTopLightMass = \"{0:.2f}\".format(value)\n",
    "        \n",
    "    \n",
    "    def __process_psm_modifications(self, modifications):\n",
    "        mod_locs = list(map(int, re.findall(self.__psm_cys_mod_pattern, modifications)))\n",
    "        return mod_locs\n",
    "    \n",
    "    def get_found_modifications(self):\n",
    "        sqlStr = \"SELECT * FROM FoundModifications\"\n",
    "        df = pd.read_sql(sqlStr, self.__connection)\n",
    "        return df\n",
    "    \n",
    "    def get_target_psms(self):\n",
    "        sqlStr = \"\"\"\n",
    "        SELECT\n",
    "        Sequence,\n",
    "        ModifiedSequence,\n",
    "        Modifications,\n",
    "        ParentProteinAccessions,\n",
    "        ParentProteinDescriptions,\n",
    "        SpectrumFileName,\n",
    "        QuanChannel,\n",
    "        QuanValueIsoTOPLight,\n",
    "        QuanValueIsoTOPHeavy\n",
    "        FROM TargetPsms\n",
    "        WHERE (QuanChannelID = 1 OR QuanChannelID = 2)\n",
    "        \"\"\"\n",
    "        df = pd.read_sql(sqlStr, self.__connection)\n",
    "        \n",
    "        df['mod_locs'] = df.Modifications.apply(self.__process_psm_modifications)\n",
    "        df['str_mod_locs'] = df['mod_locs'].astype(str)\n",
    "        df['EXPERIMENT'] = df.SpectrumFileName.str.extract(self.__exp_pattern)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def __process_modifications(self, modifications):\n",
    "        match = self.__peptide_mod_pattern.match(modifications)\n",
    "        if match:\n",
    "            mod_locs = list(map(int, re.findall(self.__peptide_cys_mod_pattern, match.group(1))))\n",
    "            return mod_locs\n",
    "        \n",
    "    \n",
    "    def __create_run_counter(self, row, experiments=['KEA_EN801', 'KEA_EN802', 'KEA_EN803']):\n",
    "        sequence = row['Sequence']\n",
    "        mod_locs = str(row['str_mod_locs'])\n",
    "        targetPsmsDF = self.__target_psms\n",
    "        \n",
    "        psms = targetPsmsDF[(targetPsmsDF.Sequence == sequence) & (targetPsmsDF['str_mod_locs'] == mod_locs)]\n",
    "        psm_exps = list(psms['EXPERIMENT'])\n",
    "        run_counter = [i in psms_exps for i in experiments]\n",
    "\n",
    "        return str(run_counter)\n",
    "    \n",
    "    def __get_global_mod_position(self, row):\n",
    "        data_cache_name = 'target_prot_sequences'\n",
    "        \n",
    "        if not data_cache_name in self.__data_cache.keys():\n",
    "            sqlStr = \"\"\"\n",
    "                        SELECT\n",
    "                        t1.PeptideGroupID,t3.Sequence\n",
    "                        FROM TargetPeptideGroups t1,\n",
    "                        TargetPeptideGroupsTargetProteins t2,\n",
    "                        TargetProteins t3\n",
    "                        WHERE t1.PeptideGroupID = t2.TargetPeptideGroupsPeptideGroupID\n",
    "                        AND t2.TargetProteinsUniqueSequenceID = t3.UniqueSequenceID\n",
    "                    \"\"\"\n",
    "            \n",
    "            df = pd.read_sql(sqlStr, self.__connection)\n",
    "            self.__data_cache[data_cache_name] = df\n",
    "            \n",
    "        peptide_sequence = row['Sequence']\n",
    "        \n",
    "        local_positions = [int(numeric_string) for numeric_string in  row['mod_locs']]\n",
    "        peptideGroupID = row['PeptideGroupID']\n",
    "        \n",
    "        df = self.__data_cache[data_cache_name]\n",
    "        proteinSequences = df[df['PeptideGroupID'] == peptideGroupID]['Sequence']\n",
    "        \n",
    "        peptide_starts = []\n",
    "        for proteinSequence in proteinSequences.values:\n",
    "            peptide_starts.append((proteinSequence.find(peptide_sequence)))\n",
    "            \n",
    "        global_positions = []\n",
    "        for peptide_start in peptide_starts:      \n",
    "            pos_strings = []\n",
    "\n",
    "            for local_position in local_positions:\n",
    "                global_pos = np.nan if peptide_start == -1 else (local_position + peptide_start)\n",
    "                pos_strings.append('C{0}'.format(global_pos))\n",
    "\n",
    "            global_positions.append(','.join(pos_strings))\n",
    "            \n",
    "        \n",
    "        return global_positions   \n",
    "    \n",
    "    def __create_ip2peptide(self, row):\n",
    "\n",
    "        modifications = row['Modifications_best_positions']\n",
    "        sequence = row['Sequence']\n",
    "        mod_locs = row['mod_locs']\n",
    "        \n",
    "        mass = modifications\n",
    "        if 'isoTOP TEV heavy' in modifications:\n",
    "            mass = self.__isoTopHeavyMass\n",
    "        elif 'isoTOP TEV Light' in modifications:\n",
    "            mass = self.__isoTopLightMass\n",
    "            \n",
    "        for mod_loc in mod_locs:\n",
    "            sequence = '{0}C({1}){2}'.format(sequence[0:mod_loc-1], mass, sequence[mod_loc:])\n",
    "\n",
    "        return sequence\n",
    "\n",
    "\n",
    "    def __extract_values(self, binary_data, n=None, dataType=None):\n",
    "        \"\"\"\n",
    "        values: bytes from the blob\n",
    "        n: number of channels\n",
    "        t: type of data\n",
    "            'decimal' for values in decimal format such as Abundances\n",
    "            'integer_number' for values such as 'Found in'\n",
    "\n",
    "        \"\"\"\n",
    "        result = []\n",
    "\n",
    "        if dataType == DataType.Float:\n",
    "            for i in range(n):\n",
    "                sub = binary_data[9*i:9*i+8]\n",
    "                result.append(struct.unpack(\"d\",sub)[0])\n",
    "        else:\n",
    "            return binary_data\n",
    "\n",
    "        if len(result) == 1:\n",
    "            return result[0]\n",
    "        else:\n",
    "            return result\n",
    "    \n",
    "    \n",
    "    def get_target_peptides_from_pdresult(self):\n",
    "        sqlStr = \"\"\"\n",
    "            SELECT\n",
    "            PeptideGroupID, \n",
    "            Checked,\n",
    "            Confidence,\n",
    "            Sequence,\n",
    "            Modifications_all_positions,\n",
    "            Modifications_best_positions,\n",
    "            Contaminant,\n",
    "            QvalityPEP,\n",
    "            Qvalityqvalue,\n",
    "            ParentProteinGroupCount,\n",
    "            ParentProteinCount,\n",
    "            PsmCount,\n",
    "            MasterProteinAccessions,\n",
    "            MissedCleavages,\n",
    "            TheoreticalMass,\n",
    "            QuanInfo,\n",
    "            IonsScoreMascot,\n",
    "            ConfidenceMascot,\n",
    "            PercolatorqValueMascot,\n",
    "            PercolatorPEPMascot,\n",
    "            AbundanceRatios,\n",
    "            Abundances,\n",
    "            FoundinSamples\n",
    "            FROM TargetPeptideGroups tpg\n",
    "            WHERE AbundanceRatios IS NOT NULL LIMIT 10;\n",
    "            \"\"\"\n",
    "        \n",
    "        df = pd.read_sql(sqlStr, self.__connection)\n",
    "        \n",
    "        df['mod_locs'] = df['Modifications_best_positions'].apply(self.__process_modifications)\n",
    "        \n",
    "        df['ip2_peptide'] = df.apply(self.__create_ip2peptide, axis=1)\n",
    "        \n",
    "        df['str_mod_locs'] = df['mod_locs'].astype(str) # To help with merge\n",
    "        df['run_counter'] = df.apply(self.__create_run_counter, axis=1)       \n",
    "        \n",
    "        df['AbundanceRatios'] = df['AbundanceRatios'].apply(self.__extract_values, n=1, dataType=DataType.Float)\n",
    "        df['Log2Ratio'] = df['AbundanceRatios'].apply(np.log2)\n",
    "        \n",
    "        df['ptm_indices'] = df.apply(self.__get_global_mod_position, axis=1)\n",
    "        \n",
    "        df = df.drop(['Abundances', 'FoundinSamples'], axis=1)\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def get_target_peptides(self):\n",
    "        # TODO: Look for any xlsx file\n",
    "        file_path = \"{0}/KEA_isoTOP_DN_High_Med_All.xlsx\".format(self.__pd_study_dir)\n",
    "        df = pd.read_excel(file_path)\n",
    "        ## Clean up dataframe\n",
    "        df = df[~df['Abundance Ratio (log2): (IsoTOP Light) / (IsoTOP Heavy)'].isnull()]\n",
    "        df['mod_locs'] = df['Modifications'].apply(self.__process_modifications)\n",
    "        df['run_counter'] = df.apply(self.__create_run_counter, axis=1)\n",
    "        \n",
    "        return df\n",
    "\n",
    "pep_generator = PeptideFromPD2_1Generator()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "peptide_from_pdresultsDF = pep_generator.get_target_peptides_from_pdresult()\n",
    "peptide_from_pdresultsDF.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sequence = 'SDFCSDFSDCSDFSDFSDF'\n",
    "\n",
    "mod_loc=4\n",
    "mass = '123.00'\n",
    "\n",
    "sequence[0:mod_loc-1] + 'C' + mass + sequence[mod_loc:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = {}\n",
    "\n",
    "## Transfer some values directly\n",
    "data['uniprot_ids'] = peptide_from_pdresultsDF['MasterProteinAccessions']\n",
    "data['area_ratio'] = peptide_from_pdresultsDF['AbundanceRatios']\n",
    "data['sequence'] = peptide_from_pdresultsDF['Sequence']\n",
    "\n",
    "\n",
    "\n",
    "# Do later\n",
    "## TODO: Global PTM\n",
    "data['ptm_indices'] = peptide_from_pdresultsDF['ptm_indices']\n",
    "## Detailed protein annot\n",
    "data['annotation'] = None\n",
    "## The IP2 semicolon array that RunCounter is made from\n",
    "data['unique1'] = None\n",
    "\n",
    "data['run_counter'] = peptide_from_pdresultsDF['run_counter']\n",
    "## Decoy is always false as the SQL Takes care of that. \n",
    "data['decoy'] = False\n",
    "## TODO: Create ip2_peptide\n",
    "ip2_peptide=peptide_from_pdresultsDF['ip2_peptide']\n",
    "\n",
    "df = pd.DataFrame(data=data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def __init_peptide(self, row):\n",
    "    peptide = Peptide(sequence=row['sequence'],\n",
    "                      mod_locs=row['mod_locs'],\n",
    "                      ptm_indices=row['ptm_indices'],\n",
    "                      area_ratio=row['area_ratio'],\n",
    "                      area_ratios=row['area_ratios'],\n",
    "                      annotation=row['annotation'],\n",
    "                      uniprot_ids=row['uniprot_ids'],\n",
    "                      run_counter=row['run_counter'],\n",
    "                      decoy=row['decoy'],\n",
    "                      unique1=row['UNIQUE_1'],\n",
    "                      ip2_peptide=row['ip2_peptide'])\n",
    "\n",
    "        return peptide\n",
    "\n",
    "df.apply(__init_peptide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pepgroup_df[pepgroup_df.Sequence == 'CGEEIAVQFVDMVK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = b'\\x06\\x00\\x00\\x00c@sA\\x01\\xfe\\xff\\xffG\\x8b\\x7feA\\x01'\n",
    "\n",
    "from enum import Enum\n",
    "\n",
    "class DataType(Enum):\n",
    "    Float = 1\n",
    "\n",
    "def extract_values(binary_data, n=None, dataType=None):\n",
    "    \"\"\"\n",
    "    values: bytes from the blob\n",
    "    n: number of channels\n",
    "    t: type of data\n",
    "        'decimal' for values in decimal format such as Abundances\n",
    "        'integer_number' for values such as 'Found in'\n",
    "\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    \n",
    "    if dataType == DataType.Float:\n",
    "        for i in range(n):\n",
    "            sub = binary_data[9*i:9*i+8]\n",
    "            result.append(struct.unpack(\"d\",sub)[0])\n",
    "    else:\n",
    "        return binary_data\n",
    "\n",
    "    if len(result) == 1:\n",
    "        return result[0]\n",
    "    else:\n",
    "        return result\n",
    "    \n",
    "file_path = \"/usca/asperapoc/NB-CPACT/NB-CPACT-NIBR/NIBR_loaded_UCB_EN80/Analysis/PD2.1/KEA_isoTOP_DN_All.pdResult\"\n",
    "pd_connection = sqlite3.connect(file_path)\n",
    "\n",
    "sqlStr = \"\"\"\n",
    "            SELECT Sequence, Abundances, AbundanceRatios, FoundInSamples FROM TargetPeptideGroups tpg \n",
    "            WHERE AbundanceRatios IS NOT NULL AND Sequence = 'CGEEIAVQFVDMVK'\n",
    "        \"\"\"\n",
    "targetPeptideGroupsDF = pd.read_sql(sqlStr, pd_connection)\n",
    "print(targetPeptideGroupsDF.AbundanceRatios.apply(extract_values, n=1, dataType=DataType.Float).apply(np.log2))\n",
    "print(targetPeptideGroupsDF.Abundances.apply(extract_values, n=2, dataType=DataType.Float))\n",
    "print(targetPeptideGroupsDF.FoundinSamples.apply(extract_values, n=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "peptide_df[peptide_df.Sequence == 'CGEEIAVQFVDMVK'].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def unpack_type(barray, n, t):\n",
    "    \"\"\"\n",
    "    extract BLOB from pdResult file\n",
    "    barray: barray that holds blob\n",
    "    n: number of channels\n",
    "    t: type of data\n",
    "        'decimal' for values in decimal format such as Abundances\n",
    "        'integer_number' for values such as 'Found in'\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    tmp = []\n",
    "    if barray:\n",
    "        if t == 'decimal':\n",
    "            for i in range(n):\n",
    "                tmp.append(struct.unpack(\"d\",barray[9*i:9*i+8]))\n",
    "        if ((t == 'integer_number') or (t == 'integer_text')):\n",
    "            for i in range(n):\n",
    "                tmp.append(struct.unpack(\"i\",df[5*i:5*i+4]))\n",
    "    # take care of the missing values     \n",
    "    else: \n",
    "        if t == 'decimal':\n",
    "            tmp = [0.0]*n    \n",
    "        if ((t == 'integer_number') or (t == 'integer_text')):\n",
    "            tmp = [0]*n\n",
    "\n",
    "    return tmp\n",
    "\n",
    "\n",
    "barray = b'{\\x14\\xaeG\\xe1z\\x84?\\x01'\n",
    "unpack_type(barray, 5, 'decimal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
